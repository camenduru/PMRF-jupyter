{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/PMRF-jupyter/blob/main/PMRF_jupyter.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/camenduru/PMRF-hf /content/PMRF\n",
        "%cd /content/PMRF\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "!pip install git+https://github.com/XPixelGroup/BasicSR facexlib realesrgan lightning wandb torch-ema einops timm torch-fidelity\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/PMRF/raw/main/config.json -d /content/PMRF/model -o config.json\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/PMRF/resolve/main/model.safetensors -d /content/PMRF/model -o model.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/PMRF/resolve/main/RealESRGAN_x4plus.pth -d /content/PMRF/pretrained_models -o RealESRGAN_x4plus.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/RealESRGAN_x2plus.pth -d /content/PMRF/pretrained_models -o RealESRGAN_x2plus.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://github.com/toshas/torch-fidelity/releases/download/v0.2.0/weights-inception-2015-12-05-6726825d.pth -d /content/PMRF/pretrained_models -o weights-inception-2015-12-05-6726825d.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content/PMRF\n",
        "\n",
        "# Some of the implementations below are adopted from\n",
        "# https://huggingface.co/spaces/sczhou/CodeFormer and https://huggingface.co/spaces/wzhouxiff/RestoreFormerPlusPlus\n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import torch\n",
        "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
        "from basicsr.utils import img2tensor, tensor2img\n",
        "from facexlib.utils.face_restoration_helper import FaceRestoreHelper\n",
        "from realesrgan.utils import RealESRGANer\n",
        "\n",
        "from lightning_models.mmse_rectified_flow import MMSERectifiedFlow\n",
        "\n",
        "MAX_SEED = 10000\n",
        "device = \"cuda\"\n",
        "\n",
        "def set_realesrgan():\n",
        "    use_half = False\n",
        "    if torch.cuda.is_available():  # set False in CPU/MPS mode\n",
        "        no_half_gpu_list = [\"1650\", \"1660\"]  # set False for GPUs that don't support f16\n",
        "        if not True in [\n",
        "            gpu in torch.cuda.get_device_name(0) for gpu in no_half_gpu_list\n",
        "        ]:\n",
        "            use_half = True\n",
        "\n",
        "    model = RRDBNet(\n",
        "        num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=2,\n",
        "    )\n",
        "    upsampler = RealESRGANer(\n",
        "        scale=2,\n",
        "        model_path=\"/content/PMRF/pretrained_models/RealESRGAN_x2plus.pth\",\n",
        "        model=model,\n",
        "        tile=400,\n",
        "        tile_pad=40,\n",
        "        pre_pad=0,\n",
        "        half=use_half,\n",
        "    )\n",
        "    return upsampler\n",
        "\n",
        "upsampler = set_realesrgan()\n",
        "pmrf = MMSERectifiedFlow.from_pretrained(\"/content/PMRF/model\").to(device=device)\n",
        "\n",
        "def generate_reconstructions(pmrf_model, x, y, non_noisy_z0, num_flow_steps, device):\n",
        "    source_dist_samples = pmrf_model.create_source_distribution_samples(\n",
        "        x, y, non_noisy_z0\n",
        "    )\n",
        "    dt = (1.0 / num_flow_steps) * (1.0 - pmrf_model.hparams.eps)\n",
        "    x_t_next = source_dist_samples.clone()\n",
        "    t_one = torch.ones(x.shape[0], device=device)\n",
        "    for i in tqdm(range(num_flow_steps)):\n",
        "        num_t = (i / num_flow_steps) * (\n",
        "            1.0 - pmrf_model.hparams.eps\n",
        "        ) + pmrf_model.hparams.eps\n",
        "        v_t_next = pmrf_model(x_t=x_t_next, t=t_one * num_t, y=y).to(x_t_next.dtype)\n",
        "        x_t_next = x_t_next.clone() + v_t_next * dt\n",
        "\n",
        "    return x_t_next.clip(0, 1)\n",
        "\n",
        "def resize(img, size):\n",
        "    # From https://github.com/sczhou/CodeFormer/blob/master/facelib/utils/face_restoration_helper.py\n",
        "    h, w = img.shape[0:2]\n",
        "    scale = size / min(h, w)\n",
        "    h, w = int(h * scale), int(w * scale)\n",
        "    interp = cv2.INTER_AREA if scale < 1 else cv2.INTER_LINEAR\n",
        "    return cv2.resize(img, (w, h), interpolation=interp)\n",
        "\n",
        "@torch.inference_mode()\n",
        "def enhance_face(img, face_helper, has_aligned, num_flow_steps, scale=2):\n",
        "    face_helper.clean_all()\n",
        "    if has_aligned:  # The inputs are already aligned\n",
        "        img = cv2.resize(img, (512, 512), interpolation=cv2.INTER_LINEAR)\n",
        "        face_helper.cropped_faces = [img]\n",
        "    else:\n",
        "        face_helper.read_image(img)\n",
        "        face_helper.input_img = resize(face_helper.input_img, 640)\n",
        "        face_helper.get_face_landmarks_5(only_center_face=False, eye_dist_threshold=5)\n",
        "        face_helper.align_warp_face()\n",
        "    if len(face_helper.cropped_faces) == 0:\n",
        "        raise Exception(\"Could not identify any face in the image.\")\n",
        "    if has_aligned and len(face_helper.cropped_faces) > 1:\n",
        "        raise Exception(\n",
        "            \"You marked that the input image is aligned, but multiple faces were detected.\"\n",
        "        )\n",
        "\n",
        "    # face restoration\n",
        "    for i, cropped_face in tqdm(enumerate(face_helper.cropped_faces)):\n",
        "        cropped_face_t = img2tensor(cropped_face / 255.0, bgr2rgb=True, float32=True)\n",
        "        cropped_face_t = cropped_face_t.unsqueeze(0).to(device)\n",
        "\n",
        "        output = generate_reconstructions(\n",
        "            pmrf,\n",
        "            torch.zeros_like(cropped_face_t),\n",
        "            cropped_face_t,\n",
        "            None,\n",
        "            num_flow_steps,\n",
        "            device,\n",
        "        )\n",
        "        restored_face = tensor2img(\n",
        "            output.to(torch.float32).squeeze(0), rgb2bgr=True, min_max=(0, 1)\n",
        "        )\n",
        "        restored_face = restored_face.astype(\"uint8\")\n",
        "        face_helper.add_restored_face(restored_face)\n",
        "\n",
        "    if not has_aligned:\n",
        "        # upsample the background\n",
        "        # Now only support RealESRGAN for upsampling background\n",
        "        bg_img = upsampler.enhance(img, outscale=scale)[0]\n",
        "        face_helper.get_inverse_affine(None)\n",
        "        # paste each restored face to the input image\n",
        "        restored_img = face_helper.paste_faces_to_input_image(upsample_img=bg_img)\n",
        "        return face_helper.cropped_faces, face_helper.restored_faces, restored_img\n",
        "    else:\n",
        "        return face_helper.cropped_faces, face_helper.restored_faces, None\n",
        "\n",
        "\n",
        "@torch.inference_mode()\n",
        "def inference(\n",
        "    img_path,\n",
        "    randomize_seed,\n",
        "    aligned,\n",
        "    scale,\n",
        "    num_flow_steps,\n",
        "    seed,\n",
        "):\n",
        "    if img_path is None:\n",
        "        raise Exception(\"Please upload an image before submitting.\")\n",
        "    if randomize_seed:\n",
        "        seed = random.randint(0, MAX_SEED)\n",
        "    torch.manual_seed(seed)\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "    h, w = img.shape[0:2]\n",
        "    if h > 4500 or w > 4500:\n",
        "        raise Exception(\"Image size too large.\")\n",
        "\n",
        "    face_helper = FaceRestoreHelper(\n",
        "        scale,\n",
        "        face_size=512,\n",
        "        crop_ratio=(1, 1),\n",
        "        det_model=\"retinaface_resnet50\",\n",
        "        save_ext=\"png\",\n",
        "        use_parse=True,\n",
        "        device=device,\n",
        "        model_rootpath=None,\n",
        "    )\n",
        "\n",
        "    has_aligned = aligned\n",
        "    cropped_face, restored_faces, restored_img = enhance_face(\n",
        "        img, face_helper, has_aligned, num_flow_steps=num_flow_steps, scale=scale\n",
        "    )\n",
        "    if has_aligned:\n",
        "        output = restored_faces[0]\n",
        "    else:\n",
        "        output = restored_img\n",
        "\n",
        "    output = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n",
        "    for i, restored_face in enumerate(restored_faces):\n",
        "        restored_faces[i] = cv2.cvtColor(restored_face, cv2.COLOR_BGR2RGB)\n",
        "    torch.cuda.empty_cache()\n",
        "    return output, restored_faces if len(restored_faces) > 1 else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_image, restored_faces = inference(\"/content/PMRF/examples/00000085.png\", randomize_seed=False, aligned=True, scale=1, num_flow_steps=25, seed=42)\n",
        "output_image_bgr = cv2.cvtColor(output_image, cv2.COLOR_RGB2BGR)\n",
        "cv2.imwrite(\"/content/PMRF/restored_00000085.png\", output_image_bgr)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
